{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Je7yataA2m"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b4WISscZgCEv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-13 17:10:55.249832: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wZG1t9Wjh6de"
      },
      "outputs": [],
      "source": [
        "base_path = os.path.join(\"../\", \"data\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KnYZjQOjr2WX"
      },
      "source": [
        "# get image's paths: x_train and x_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6Gk8GJZYmC1J"
      },
      "outputs": [],
      "source": [
        "x_train_file = os.path.join(base_path, \"preprocessed_train.txt\")\n",
        "with open(x_train_file) as ptf:\n",
        "  x_train = ptf.read().splitlines()\n",
        "ptf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-Zv9sWAwmzlc",
        "outputId": "62ecce4a-9587-40bb-a815-484fdf13cfb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'preprocessed/train/10000_train.png'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "84I0snhAm9NU"
      },
      "outputs": [],
      "source": [
        "x_valid_file = os.path.join(base_path, \"preprocessed_valid.txt\")\n",
        "with open(x_valid_file) as pvf:\n",
        "  x_valid = pvf.read().splitlines()\n",
        "pvf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Hl8Fre7GXo3j",
        "outputId": "a9d930f4-c4f2-4204-cacc-a5d80f508b50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'preprocessed/valid/1000_valid.png'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_valid[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EFiTne_Br543"
      },
      "source": [
        "## get image's paths: x_train_gaussian and x_valid_gaussian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2oKKUq9CsUQx"
      },
      "outputs": [],
      "source": [
        "x_train_gaussian_file = os.path.join(base_path, \"gaussian_train.txt\")\n",
        "with open(x_train_gaussian_file) as xgtf:\n",
        "  x_gaussian_train = xgtf.read().splitlines()\n",
        "xgtf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ISO3FomAoaEY",
        "outputId": "7403c040-241e-4790-8ba9-32d52766f1bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'gaussian_images/train/10000_train_blured.png'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_gaussian_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DKiNdk62cGz0"
      },
      "outputs": [],
      "source": [
        "x_valid_gaussian_file = os.path.join(base_path, \"gaussian_valid.txt\")\n",
        "with open(x_valid_gaussian_file) as xgvf:\n",
        "  x_gaussian_valid = xgvf.read().splitlines()\n",
        "xgvf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7M55rUJco_LY",
        "outputId": "0ecc41ae-e6f8-42dc-d963-c58c041d4e01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'gaussian_images/valid/1000_valid_blured.png'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_gaussian_valid[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czIJrUAcpBRP",
        "outputId": "530a1af4-950a-419c-9a50-80ee731f0503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones para imagenes originales: 25462 2121\n",
            "Dimensiones para imagenes gaussianas: 25462 2121\n"
          ]
        }
      ],
      "source": [
        "print(\"Dimensiones para imagenes originales:\", len(x_train), len(x_valid))\n",
        "print(\"Dimensiones para imagenes gaussianas:\", len(x_gaussian_train), len(x_gaussian_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train[:15000]\n",
        "x_valid = x_valid[:500]\n",
        "x_gaussian_train = x_gaussian_train[:15000]\n",
        "x_gaussian_valid = x_gaussian_valid[:500]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OKPjRLxHazVr"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DBWJCC9gdz5t"
      },
      "outputs": [],
      "source": [
        "OW, NW = 64, 64\n",
        "OH, NH = 88, 88"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pyq5GOZqnq4w"
      },
      "outputs": [],
      "source": [
        "# Crear las listas para las imágenes originales y con ruido\n",
        "original_images = []\n",
        "noisy_images = []\n",
        "\n",
        "# Leer las imágenes originales y con ruido\n",
        "for or_img, ns_img in zip(x_train, x_gaussian_train):\n",
        "\n",
        "    # Leer las imágenes en escala de grises\n",
        "    original_image = cv.imread(os.path.join(base_path, or_img))\n",
        "    noisy_image = cv.imread(os.path.join(base_path, ns_img))\n",
        "\n",
        "    oh, ow, _ = original_image.shape\n",
        "    nh, nw, _ = noisy_image.shape\n",
        "\n",
        "\n",
        "    original_image = cv.resize(original_image, (OW, OH), interpolation = cv.INTER_AREA)\n",
        "    noisy_image = cv.resize(noisy_image, (NW, NH), interpolation = cv.INTER_AREA)\n",
        "\n",
        "    # Normalizar los valores de píxeles en el rango [0, 1]\n",
        "    original_image = original_image.astype(np.float32) / 255.0\n",
        "    noisy_image = noisy_image.astype(np.float32) / 255.0\n",
        "\n",
        "    # Agregar las imágenes a las listas\n",
        "    original_images.append(original_image)\n",
        "    noisy_images.append(noisy_image)\n",
        "\n",
        "# Asegurarse de que las imágenes tengan la forma adecuada\n",
        "original_images = np.expand_dims(original_images, axis=-1)\n",
        "noisy_images = np.expand_dims(noisy_images, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "k72NMW4Ugbm2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 88, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 88, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 44, 32, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 44, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 22, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 22, 16, 64)        36928     \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 44, 32, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 44, 32, 32)        18464     \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 88, 64, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 88, 64, 3)         867       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,651\n",
            "Trainable params: 75,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-13 17:13:56.550666: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Definir la arquitectura del autoencoder\n",
        "\n",
        "# Definir la arquitectura del autoencoder\n",
        "def build_autoencoder():\n",
        "    # Encoder\n",
        "    input_img = tf.keras.Input(shape=(88, 64, 3))\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Autoencoder model\n",
        "    autoencoder = tf.keras.Model(input_img, decoded)\n",
        "    return autoencoder\n",
        "\n",
        "# Construir y compilar el modelo del autoencoder\n",
        "autoencoder = build_autoencoder()\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/training.py\", line 998, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/training.py\", line 1092, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 143, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 700, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/metrics/metrics.py\", line 3669, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 962, in sparse_categorical_matches\n        y_true = tf.squeeze(y_true, [-1])\n\n    ValueError: Can not squeeze dim[3], expected a dimension of 1, got 3 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](remove_squeezable_dimensions/Squeeze)' with input shapes: [?,88,64,3].\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m Y_train \u001b[39m=\u001b[39m noisy_images\n\u001b[1;32m      8\u001b[0m \u001b[39m# Entrenar el autoencoder\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(Y_train, X_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/var/folders/wj/_wkdntf14_3d9wfq80151hjc0000gp/T/__autograph_generated_filemm3c943c.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/training.py\", line 998, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/training.py\", line 1092, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 143, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 700, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/metrics/metrics.py\", line 3669, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/Users/brandon/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 962, in sparse_categorical_matches\n        y_true = tf.squeeze(y_true, [-1])\n\n    ValueError: Can not squeeze dim[3], expected a dimension of 1, got 3 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](remove_squeezable_dimensions/Squeeze)' with input shapes: [?,88,64,3].\n"
          ]
        }
      ],
      "source": [
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Cargar los datos de entrenamiento (ejemplo)\n",
        "# Aquí debes reemplazar 'X_train' con tus propios datos de entrenamiento\n",
        "X_train = original_images\n",
        "Y_train = noisy_images\n",
        "\n",
        "# Entrenar el autoencoder\n",
        "autoencoder.fit(Y_train, X_train, epochs=10, batch_size=16)\n",
        "\n",
        "# Realizar predicciones en nuevos datos\n",
        "# Aquí debes reemplazar 'X_test' con tus propios datos de prueba\n",
        "#X_test = np.random.rand(10, 128, 100, 3)\n",
        "#predictions = autoencoder.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
